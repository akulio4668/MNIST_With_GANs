{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets.mnist import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(in_shape=(28,28,1)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), padding=\"same\", input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), padding=\"same\")) \n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    # compile model\n",
    "    adam_opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam_opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def load_and_norm_samples():\n",
    "    (train_data, _), (_, _) = load_data()\n",
    "    training_images = np.expand_dims(train_data, axis = -1)\n",
    "    training_images = training_images.astype('float32')\n",
    "    training_images = training_images / 255.0\n",
    "    return training_images\n",
    "    \n",
    "def generate_real_images(dataset, num_samples):\n",
    "    idx = np.random.randint(0, dataset.shape[0], num_samples)\n",
    "    gen_data = dataset[idx]\n",
    "    gen_labels = np.ones((num_samples, 1))\n",
    "    return gen_data, gen_labels\n",
    "    \n",
    "def generate_fake_images(num_samples):\n",
    "    gen_data = np.random.rand(28 * 28 * num_samples)\n",
    "    gen_data = gen_data.reshape((num_samples, 28, 28, 1))\n",
    "    gen_labels = np.zeros((num_samples, 1))\n",
    "    return gen_data, gen_labels\n",
    "\n",
    "def train_discriminator(model, dataset, num_periods=100, batch_size=256):\n",
    "    half_batch_size = int(batch_size / 2)\n",
    "    for epoch in range(num_periods):\n",
    "        image_real, label_real = generate_real_images(dataset, half_batch_size)\n",
    "        _, real_acc = model.train_on_batch(image_real, label_real)\n",
    "        image_fake, label_fake = generate_fake_images(half_batch_size)\n",
    "        _, fake_acc = model.train_on_batch(image_fake, label_fake)\n",
    "        print('>%d real=%.0f%% fake=%.0f%%' % (epoch, real_acc, fake_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0 real=1% fake=1%\n",
      ">1 real=1% fake=1%\n",
      ">2 real=1% fake=1%\n",
      ">3 real=1% fake=1%\n",
      ">4 real=1% fake=1%\n",
      ">5 real=1% fake=1%\n",
      ">6 real=1% fake=1%\n",
      ">7 real=1% fake=1%\n",
      ">8 real=1% fake=1%\n",
      ">9 real=1% fake=1%\n",
      ">10 real=1% fake=1%\n",
      ">11 real=1% fake=1%\n",
      ">12 real=1% fake=1%\n",
      ">13 real=1% fake=1%\n",
      ">14 real=1% fake=1%\n",
      ">15 real=1% fake=1%\n",
      ">16 real=1% fake=1%\n",
      ">17 real=1% fake=1%\n",
      ">18 real=1% fake=1%\n",
      ">19 real=1% fake=1%\n",
      ">20 real=1% fake=1%\n",
      ">21 real=1% fake=1%\n",
      ">22 real=1% fake=1%\n",
      ">23 real=1% fake=1%\n",
      ">24 real=1% fake=1%\n",
      ">25 real=1% fake=1%\n",
      ">26 real=1% fake=1%\n",
      ">27 real=1% fake=1%\n",
      ">28 real=1% fake=1%\n",
      ">29 real=1% fake=1%\n",
      ">30 real=1% fake=1%\n",
      ">31 real=1% fake=1%\n",
      ">32 real=1% fake=1%\n",
      ">33 real=1% fake=1%\n",
      ">34 real=1% fake=1%\n",
      ">35 real=1% fake=1%\n",
      ">36 real=1% fake=1%\n",
      ">37 real=1% fake=1%\n",
      ">38 real=1% fake=1%\n",
      ">39 real=1% fake=1%\n",
      ">40 real=1% fake=1%\n",
      ">41 real=1% fake=1%\n",
      ">42 real=1% fake=1%\n",
      ">43 real=1% fake=1%\n",
      ">44 real=1% fake=1%\n",
      ">45 real=1% fake=1%\n",
      ">46 real=1% fake=1%\n",
      ">47 real=1% fake=1%\n",
      ">48 real=1% fake=1%\n",
      ">49 real=1% fake=1%\n",
      ">50 real=1% fake=1%\n",
      ">51 real=1% fake=1%\n",
      ">52 real=1% fake=1%\n",
      ">53 real=1% fake=1%\n",
      ">54 real=1% fake=1%\n",
      ">55 real=1% fake=1%\n",
      ">56 real=1% fake=1%\n",
      ">57 real=1% fake=1%\n",
      ">58 real=1% fake=1%\n",
      ">59 real=1% fake=1%\n",
      ">60 real=1% fake=1%\n",
      ">61 real=1% fake=1%\n",
      ">62 real=1% fake=1%\n",
      ">63 real=1% fake=1%\n",
      ">64 real=1% fake=1%\n",
      ">65 real=1% fake=1%\n",
      ">66 real=1% fake=1%\n",
      ">67 real=1% fake=1%\n",
      ">68 real=1% fake=1%\n",
      ">69 real=1% fake=1%\n",
      ">70 real=1% fake=1%\n",
      ">71 real=1% fake=1%\n",
      ">72 real=1% fake=1%\n",
      ">73 real=1% fake=1%\n",
      ">74 real=1% fake=1%\n",
      ">75 real=1% fake=1%\n",
      ">76 real=1% fake=1%\n",
      ">77 real=1% fake=1%\n",
      ">78 real=1% fake=1%\n",
      ">79 real=1% fake=1%\n",
      ">80 real=1% fake=1%\n",
      ">81 real=1% fake=1%\n",
      ">82 real=1% fake=1%\n",
      ">83 real=1% fake=1%\n",
      ">84 real=1% fake=1%\n",
      ">85 real=1% fake=1%\n",
      ">86 real=1% fake=1%\n",
      ">87 real=1% fake=1%\n",
      ">88 real=1% fake=1%\n",
      ">89 real=1% fake=1%\n",
      ">90 real=1% fake=1%\n",
      ">91 real=1% fake=1%\n",
      ">92 real=1% fake=1%\n",
      ">93 real=1% fake=1%\n",
      ">94 real=1% fake=1%\n",
      ">95 real=1% fake=1%\n",
      ">96 real=1% fake=1%\n",
      ">97 real=1% fake=1%\n",
      ">98 real=1% fake=1%\n",
      ">99 real=1% fake=1%\n"
     ]
    }
   ],
   "source": [
    "model = define_discriminator()\n",
    "dataset = load_and_norm_samples()\n",
    "\n",
    "train_discriminator(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
